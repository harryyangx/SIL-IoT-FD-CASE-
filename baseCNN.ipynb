{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43729639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import manifold\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef22dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74586, 60, 2)\n",
      "(74586,)\n",
      "(7140, 60, 2)\n",
      "(7140,)\n"
     ]
    }
   ],
   "source": [
    "fault_rates = [0.5]\n",
    "\n",
    "for fault_rate in fault_rates:\n",
    "    # 加载训练数据\n",
    "    x_train = np.load('%s_x_train.npy' % fault_rate)  # 输入特征\n",
    "    y_train = np.load('%s_y_train.npy' % fault_rate)  # 标签\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "    # 加载测试数据\n",
    "    x_test = np.load('weight_%s_x_test.npy' % fault_rate)\n",
    "    y_test = np.load('weight_%s_y_test.npy' % fault_rate)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ec23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算类别权重\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "# 如果使用 GPU，将权重移到 GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c31a530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_502978/3784583002.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train = torch.tensor(x_train, dtype=torch.float32)\n",
      "/tmp/ipykernel_502978/3784583002.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "# 划分训练集和验证集（类似 validation_split=0.2）\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "# 创建 DataLoader\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea89009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch - x shape: torch.Size([32, 60, 2])\n",
      "Train batch - y shape: torch.Size([32])\n",
      "Val batch - x shape: torch.Size([32, 60, 2])\n",
      "Val batch - y shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# 查看训练集的 batch 尺寸\n",
    "for batch_x, batch_y in train_loader:\n",
    "    print(\"Train batch - x shape:\", batch_x.shape)  # 输入特征的尺寸\n",
    "    print(\"Train batch - y shape:\", batch_y.shape)  # 标签的尺寸\n",
    "    break  # 只看第一个 batch\n",
    "\n",
    "# 查看验证集的 batch 尺寸\n",
    "for batch_x, batch_y in val_loader:\n",
    "    print(\"Val batch - x shape:\", batch_x.shape)    # 输入特征的尺寸\n",
    "    print(\"Val batch - y shape:\", batch_y.shape)    # 标签的尺寸\n",
    "    break  # 只看第一个 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db75a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(BaseCNN, self).__init__()\n",
    "        \n",
    "        # 卷积层定义\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 批归一化层\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # 池化层（全局平均池化替代全连接层）\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # 输出层\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 输入 x: [batch_size, 60, 2] → 转置为 [batch_size, 2, 60]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # 卷积 + ReLU + BatchNorm\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # 全局平均池化 → [batch_size, 256, 1]\n",
    "        x = self.global_avg_pool(x)\n",
    "        \n",
    "        # 展平 → [batch_size, 256]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Dropout\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 输出层 → [batch_size, num_classes]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce17f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.4174 | Train Acc: 77.48% | Val Loss: 0.2190 | Val Acc: 90.06%\n",
      "Epoch: 1 | Train Loss: 0.2402 | Train Acc: 86.33% | Val Loss: 0.1413 | Val Acc: 94.23%\n",
      "Epoch: 2 | Train Loss: 0.2019 | Train Acc: 89.44% | Val Loss: 0.1331 | Val Acc: 91.55%\n",
      "Epoch: 3 | Train Loss: 0.1728 | Train Acc: 91.45% | Val Loss: 0.1208 | Val Acc: 96.01%\n",
      "Epoch: 4 | Train Loss: 0.1521 | Train Acc: 92.90% | Val Loss: 0.1036 | Val Acc: 96.51%\n",
      "Epoch: 5 | Train Loss: 0.1387 | Train Acc: 93.90% | Val Loss: 0.0908 | Val Acc: 96.57%\n",
      "Epoch: 6 | Train Loss: 0.1301 | Train Acc: 94.42% | Val Loss: 0.0884 | Val Acc: 97.71%\n",
      "Epoch: 7 | Train Loss: 0.1250 | Train Acc: 94.99% | Val Loss: 0.0907 | Val Acc: 96.13%\n",
      "Epoch: 8 | Train Loss: 0.1087 | Train Acc: 95.52% | Val Loss: 0.0820 | Val Acc: 97.51%\n",
      "Epoch: 9 | Train Loss: 0.1099 | Train Acc: 95.39% | Val Loss: 0.0877 | Val Acc: 97.75%\n",
      "Epoch: 10 | Train Loss: 0.1023 | Train Acc: 95.74% | Val Loss: 0.0771 | Val Acc: 98.35%\n",
      "Epoch: 11 | Train Loss: 0.1102 | Train Acc: 95.79% | Val Loss: 0.0880 | Val Acc: 97.37%\n",
      "Epoch: 12 | Train Loss: 0.0967 | Train Acc: 96.05% | Val Loss: 0.0874 | Val Acc: 95.53%\n",
      "Epoch: 13 | Train Loss: 0.0960 | Train Acc: 95.96% | Val Loss: 0.0694 | Val Acc: 98.22%\n",
      "Epoch: 14 | Train Loss: 0.0942 | Train Acc: 96.15% | Val Loss: 0.0800 | Val Acc: 97.85%\n",
      "Epoch: 15 | Train Loss: 0.0904 | Train Acc: 96.30% | Val Loss: 0.0747 | Val Acc: 96.59%\n",
      "Epoch: 16 | Train Loss: 0.0900 | Train Acc: 96.28% | Val Loss: 0.0914 | Val Acc: 97.37%\n",
      "Epoch: 17 | Train Loss: 0.0826 | Train Acc: 96.48% | Val Loss: 0.0682 | Val Acc: 98.40%\n",
      "Epoch: 18 | Train Loss: 0.0823 | Train Acc: 96.53% | Val Loss: 0.0778 | Val Acc: 95.80%\n",
      "Epoch: 19 | Train Loss: 0.0845 | Train Acc: 96.43% | Val Loss: 0.0925 | Val Acc: 95.86%\n",
      "Epoch: 20 | Train Loss: 0.0812 | Train Acc: 96.53% | Val Loss: 0.0634 | Val Acc: 98.10%\n",
      "Epoch: 21 | Train Loss: 0.0782 | Train Acc: 96.68% | Val Loss: 0.0712 | Val Acc: 96.72%\n",
      "Epoch: 22 | Train Loss: 0.0798 | Train Acc: 96.64% | Val Loss: 0.0704 | Val Acc: 98.11%\n",
      "Epoch: 23 | Train Loss: 0.0763 | Train Acc: 96.71% | Val Loss: 0.0664 | Val Acc: 97.47%\n",
      "Epoch: 24 | Train Loss: 0.0764 | Train Acc: 96.73% | Val Loss: 0.0679 | Val Acc: 97.62%\n",
      "Epoch: 25 | Train Loss: 0.0733 | Train Acc: 96.70% | Val Loss: 0.0610 | Val Acc: 98.28%\n",
      "Epoch: 26 | Train Loss: 0.0748 | Train Acc: 96.85% | Val Loss: 0.0629 | Val Acc: 98.33%\n",
      "Epoch: 27 | Train Loss: 0.0694 | Train Acc: 97.09% | Val Loss: 0.0776 | Val Acc: 96.15%\n",
      "Epoch: 28 | Train Loss: 0.0702 | Train Acc: 97.14% | Val Loss: 0.0636 | Val Acc: 98.03%\n",
      "Epoch: 29 | Train Loss: 0.0660 | Train Acc: 97.08% | Val Loss: 0.0637 | Val Acc: 98.50%\n",
      "Epoch: 30 | Train Loss: 0.0665 | Train Acc: 97.15% | Val Loss: 0.0686 | Val Acc: 98.08%\n",
      "Epoch: 31 | Train Loss: 0.0680 | Train Acc: 96.93% | Val Loss: 0.0614 | Val Acc: 98.73%\n",
      "Epoch: 32 | Train Loss: 0.0699 | Train Acc: 97.00% | Val Loss: 0.0651 | Val Acc: 97.66%\n",
      "Epoch: 33 | Train Loss: 0.0647 | Train Acc: 97.23% | Val Loss: 0.0637 | Val Acc: 97.65%\n",
      "Epoch: 34 | Train Loss: 0.0640 | Train Acc: 97.21% | Val Loss: 0.0670 | Val Acc: 98.02%\n",
      "Epoch: 35 | Train Loss: 0.0650 | Train Acc: 97.08% | Val Loss: 0.0659 | Val Acc: 98.12%\n",
      "Epoch: 36 | Train Loss: 0.0637 | Train Acc: 97.15% | Val Loss: 0.0676 | Val Acc: 97.73%\n",
      "Epoch: 37 | Train Loss: 0.0587 | Train Acc: 97.26% | Val Loss: 0.0704 | Val Acc: 98.21%\n",
      "Epoch: 38 | Train Loss: 0.0624 | Train Acc: 97.30% | Val Loss: 0.0619 | Val Acc: 98.11%\n",
      "Epoch: 39 | Train Loss: 0.0591 | Train Acc: 97.34% | Val Loss: 0.0613 | Val Acc: 97.63%\n",
      "Epoch: 40 | Train Loss: 0.0613 | Train Acc: 97.23% | Val Loss: 0.0569 | Val Acc: 98.49%\n",
      "Epoch: 41 | Train Loss: 0.0632 | Train Acc: 97.37% | Val Loss: 0.0584 | Val Acc: 97.72%\n",
      "Epoch: 42 | Train Loss: 0.0587 | Train Acc: 97.21% | Val Loss: 0.0579 | Val Acc: 98.57%\n",
      "Epoch: 43 | Train Loss: 0.0581 | Train Acc: 97.32% | Val Loss: 0.0668 | Val Acc: 97.43%\n",
      "Epoch: 44 | Train Loss: 0.0560 | Train Acc: 97.40% | Val Loss: 0.0595 | Val Acc: 98.18%\n",
      "Epoch: 45 | Train Loss: 0.0532 | Train Acc: 97.49% | Val Loss: 0.0600 | Val Acc: 97.63%\n",
      "Epoch: 46 | Train Loss: 0.0574 | Train Acc: 97.29% | Val Loss: 0.0581 | Val Acc: 98.36%\n",
      "Epoch: 47 | Train Loss: 0.0546 | Train Acc: 97.35% | Val Loss: 0.0711 | Val Acc: 97.85%\n",
      "Epoch: 48 | Train Loss: 0.0586 | Train Acc: 97.36% | Val Loss: 0.0599 | Val Acc: 98.00%\n",
      "Epoch: 49 | Train Loss: 0.0526 | Train Acc: 97.64% | Val Loss: 0.0729 | Val Acc: 97.91%\n",
      "训练日志已保存到 training_baseCNN.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 定义模型（替换为你的模型，例如 1D CNN）\n",
    "model = BaseCNN().to(device)\n",
    "\n",
    "# 定义优化器和损失函数（带类别权重）\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "EPOCHS = 50\n",
    "# 初始化一个空 DataFrame 来存储训练日志\n",
    "train_logs = pd.DataFrame(columns=[\n",
    "    'Epoch', \n",
    "    'Train Loss', \n",
    "    'Train Acc (%)', \n",
    "    'Val Loss', \n",
    "    'Val Acc (%)'\n",
    "])\n",
    "# 训练循环\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累计训练损失和准确率\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += batch_y.size(0)\n",
    "        train_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    # 计算训练集平均损失和准确率\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    # 验证集评估\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            # 累计验证损失和准确率\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += (predicted == batch_y).sum().item()\n",
    "    # 计算验证集平均损失和准确率\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    # 打印结果\n",
    "    print(f'Epoch: {epoch} | '\n",
    "          f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '\n",
    "          f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # 将当前 epoch 的结果添加到 DataFrame\n",
    "    train_logs.loc[len(train_logs)] = {\n",
    "        'Epoch': epoch + 1,\n",
    "        'Train Loss': train_loss,\n",
    "        'Train Acc (%)': train_acc,\n",
    "        'Val Loss': val_loss,\n",
    "        'Val Acc (%)': val_acc\n",
    "    }\n",
    "\n",
    "# 训练结束后保存到 Excel\n",
    "train_logs.to_excel('training_baseCNN.xlsx', index=False, engine='openpyxl')\n",
    "print(\"训练日志已保存到 training_baseCNN.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a8fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试结果已保存到 test_baseCNN.xlsx\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'model.pth')  # 保存整个模型\n",
    "model = torch.load('model.pth', weights_only=False)  # 加载整个模型\n",
    "model.eval()  # 切换到评估模式\n",
    "# 初始化存储真实标签和预测标签的列表\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "# 在测试集上推理\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # 收集标签和预测结果\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision = precision_score(all_labels, all_predictions, average='macro')  # 多分类用'macro'\n",
    "recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "# 生成混淆矩阵（后续可用于绘制）\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "# 将评估指标保存到 DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Value': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "# 将真实标签和预测标签保存到 DataFrame\n",
    "labels_df = pd.DataFrame({\n",
    "    'True_Label': all_labels,\n",
    "    'Predicted_Label': all_predictions\n",
    "})\n",
    "\n",
    "# 将混淆矩阵保存到 DataFrame\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix)\n",
    "\n",
    "# 写入 Excel 文件的不同 Sheet\n",
    "with pd.ExcelWriter('test_baseCNN.xlsx', engine='openpyxl') as writer:\n",
    "    metrics_df.to_excel(writer, sheet_name='Metrics', index=False)\n",
    "    labels_df.to_excel(writer, sheet_name='True_vs_Pred', index=False)\n",
    "    conf_matrix_df.to_excel(writer, sheet_name='Confusion_Matrix', index=False)\n",
    "\n",
    "print(\"测试结果已保存到 test_baseCNN.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
